# ğŸ”¬ NCKH - BPA and Entropy Research
### MÃ´ hÃ¬nh xÃ¡c Ä‘á»‹nh BPA vÃ  xá»­ lÃ½ xung Ä‘á»™t báº±ng Adaboost & Entropy Niá»m Tin

**TÃ¡c giáº£:** Nguyá»…n Thá»‹ Thanh Tháº£o vÃ  Ä‘á»“ng sá»±.
**NgÃ´n ngá»¯:** Python (Jupyter Notebook)

---

## ğŸ“˜ Giá»›i thiá»‡u

Trong ká»· nguyÃªn dá»¯ liá»‡u lá»›n vÃ  trÃ­ tuá»‡ nhÃ¢n táº¡o, viá»‡c **xá»­ lÃ½ thÃ´ng tin khÃ´ng cháº¯c cháº¯n** trá»Ÿ thÃ nh má»™t thÃ¡ch thá»©c lá»›n trong cÃ¡c bÃ i toÃ¡n phÃ¢n loáº¡i, Ä‘áº·c biá»‡t á»Ÿ cÃ¡c lÄ©nh vá»±c yÃªu cáº§u Ä‘á»™ tin cáº­y cao nhÆ° **y táº¿, tÃ i chÃ­nh, cháº©n Ä‘oÃ¡n lá»—i vÃ  nháº­n dáº¡ng máº«u**.

Dá»± Ã¡n nÃ y nghiÃªn cá»©u vÃ  triá»ƒn khai **má»™t mÃ´ hÃ¬nh phÃ¢n loáº¡i dá»±a trÃªn lÃ½ thuyáº¿t Dempsterâ€“Shafer (DSET)**, trong Ä‘Ã³:
- **Adaboost** Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ xÃ¡c Ä‘á»‹nh **BPA (Basic Probability Assignment)** mÃ  khÃ´ng cáº§n giáº£ Ä‘á»‹nh phÃ¢n phá»‘i dá»¯ liá»‡u.  
- **Entropy Niá»m Tin (Deng Entropy)** vÃ  **Phá»§ Ä‘á»‹nh BPA** Ä‘Æ°á»£c Ã¡p dá»¥ng Ä‘á»ƒ **giáº£m xung Ä‘á»™t thÃ´ng tin** vÃ  **nÃ¢ng cao Ä‘á»™ chÃ­nh xÃ¡c phÃ¢n loáº¡i**.

Má»¥c tiÃªu chÃ­nh:
- Tá»‘i Æ°u hÃ³a quy trÃ¬nh gÃ¡n BPA tá»« dá»¯ liá»‡u nhá» hoáº·c phÃ¢n tÃ¡n.  
- Äá» xuáº¥t cÆ¡ cháº¿ káº¿t há»£p BPA Ä‘Ã¡ng tin cáº­y hÆ¡n thÃ´ng qua phá»§ Ä‘á»‹nh vÃ  entropy.  
- á»¨ng dá»¥ng vÃ o cÃ¡c bÃ i toÃ¡n phÃ¢n loáº¡i thá»±c nghiá»‡m nhÆ° bá»™ dá»¯ liá»‡u **Iris (UCI)**.

---

## ğŸ§© PhÆ°Æ¡ng phÃ¡p nghiÃªn cá»©u

### 1ï¸âƒ£ XÃ¡c Ä‘á»‹nh BPA báº±ng Adaboost
- Ãp dá»¥ng **Adaboost vá»›i Decision Stump** lÃ m bá»™ phÃ¢n loáº¡i yáº¿u.  
- Má»—i cáº·p thuá»™c tÃ­nh Ä‘Æ°á»£c huáº¥n luyá»‡n riÃªng biá»‡t â†’ tÃ­nh BPA cho tá»«ng lá»›p.  
- Sá»­ dá»¥ng **phÆ°Æ¡ng phÃ¡p tá»· lá»‡ diá»‡n tÃ­ch (Area Ratio Method)** Ä‘á»ƒ phÃ¢n bá»• láº¡i BPA cho cÃ¡c vÃ¹ng giao nhau (táº­p há»£p má»‡nh Ä‘á» tá»•ng há»£p).  
- KhÃ´ng cáº§n giáº£ Ä‘á»‹nh phÃ¢n phá»‘i dá»¯ liá»‡u (nhÆ° Gaussian), giÃºp phÃ¹ há»£p vá»›i táº­p huáº¥n luyá»‡n nhá».

### 2ï¸âƒ£ Xá»­ lÃ½ xung Ä‘á»™t báº±ng Phá»§ Ä‘á»‹nh BPA vÃ  Entropy Niá»m Tin
- **Phá»§ Ä‘á»‹nh BPA** giÃºp khÃ´i phá»¥c thÃ´ng tin bá»‹ máº¥t trong quÃ¡ trÃ¬nh káº¿t há»£p chá»©ng cá»© mÃ¢u thuáº«n.  
- **Entropy Niá»m Tin (Deng Entropy)** dÃ¹ng Ä‘á»ƒ Ä‘o lÆ°á»ng má»©c Ä‘á»™ khÃ´ng cháº¯c cháº¯n cá»§a má»—i nguá»“n thÃ´ng tin â†’ Ä‘iá»u chá»‰nh trá»ng sá»‘ trÆ°á»›c khi há»£p nháº¥t.  
- Káº¿t há»£p cÃ¡c chá»©ng cá»© báº±ng **quy táº¯c Dempster** Ä‘á»ƒ táº¡o ra quyáº¿t Ä‘á»‹nh phÃ¢n loáº¡i cuá»‘i cÃ¹ng.

---

## âš™ï¸ Quy trÃ¬nh thá»±c hiá»‡n

1. Chuáº©n bá»‹ vÃ  chia dá»¯ liá»‡u (80% train / 20% test).  
2. Huáº¥n luyá»‡n mÃ´ hÃ¬nh Adaboost cho tá»«ng cáº·p thuá»™c tÃ­nh.  
3. TÃ­nh BPA cho tá»«ng lá»›p vÃ  má»‡nh Ä‘á» tá»•ng há»£p.  
4. Ãp dá»¥ng phá»§ Ä‘á»‹nh BPA vÃ  entropy niá»m tin Ä‘á»ƒ hiá»‡u chá»‰nh.  
5. Há»£p nháº¥t chá»©ng cá»© báº±ng quy táº¯c Dempster.  
6. PhÃ¢n loáº¡i máº«u dá»±a trÃªn BPA lá»›n nháº¥t.  
7. ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t báº±ng Accuracy, Precision, Recall, F1-score.

---

## ğŸ§ª Káº¿t quáº£ thá»±c nghiá»‡m

- **Táº­p dá»¯ liá»‡u:** Iris (UCI Repository)  
- **Sá»‘ máº«u:** 150 (3 lá»›p: Setosa, Versicolor, Virginica)  
- **Äáº·c trÆ°ng:** 4 thuá»™c tÃ­nh (chiá»u dÃ i/rá»™ng Ä‘Ã i hoa & cÃ¡nh hoa)

| Chá»‰ sá»‘ | Káº¿t quáº£ |
|--------|----------|
| Accuracy | **100.00%** (vá»›i â‰¥ 60% dá»¯ liá»‡u huáº¥n luyá»‡n) |
| Accuracy (10% train) | **>93%** |
| PhÆ°Æ¡ng phÃ¡p so sÃ¡nh | SVM, KNN, Random Forest |
| Káº¿t quáº£ | MÃ´ hÃ¬nh BPA-Adaboost vÆ°á»£t trá»™i vá» Ä‘á»™ á»•n Ä‘á»‹nh vÃ  Ä‘á»™ tin cáº­y |

> âœ… MÃ´ hÃ¬nh thá»ƒ hiá»‡n kháº£ nÄƒng **phÃ¢n loáº¡i chÃ­nh xÃ¡c vÃ  tin cáº­y cao**, ngay cáº£ khi dá»¯ liá»‡u huáº¥n luyá»‡n háº¡n cháº¿.

---

## ğŸ“Š ÄÃ³ng gÃ³p chÃ­nh

- **XÃ¢y dá»±ng mÃ´ hÃ¬nh xÃ¡c Ä‘á»‹nh BPA Ä‘á»™ng** dá»±a trÃªn trá»ng sá»‘ Adaboost.  
- **Äá» xuáº¥t phÆ°Æ¡ng phÃ¡p phá»§ Ä‘á»‹nh BPA** Ä‘á»ƒ giáº£m xung Ä‘á»™t trong quÃ¡ trÃ¬nh há»£p nháº¥t.  
- **á»¨ng dá»¥ng entropy niá»m tin (Deng entropy)** Ä‘á»ƒ Ä‘iá»u chá»‰nh trá»ng sá»‘ há»£p nháº¥t.  
- **Thá»­ nghiá»‡m vÃ  chá»©ng minh hiá»‡u quáº£** trÃªn táº­p dá»¯ liá»‡u thá»±c táº¿ vá»›i Ä‘á»™ chÃ­nh xÃ¡c cao.

---

## ğŸ§± CÃ i Ä‘áº·t vÃ  cháº¡y

### 1ï¸âƒ£ CÃ i Ä‘áº·t mÃ´i trÆ°á»ng
```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Má»Ÿ notebook
```bash
jupyter notebook Main.ipynb
```

### 3ï¸âƒ£ Cháº¡y tuáº§n tá»± tá»«ng cell Ä‘á»ƒ xem quÃ¡ trÃ¬nh:
- Tiá»n xá»­ lÃ½ dá»¯ liá»‡u  
- Huáº¥n luyá»‡n Adaboost  
- TÃ­nh BPA  
- Káº¿t há»£p Dempster + Entropy  
- PhÃ¢n tÃ­ch káº¿t quáº£

---

## ğŸ§  á»¨ng dá»¥ng tiá»m nÄƒng

- Nháº­n dáº¡ng máº«u (Pattern Recognition)  
- Cháº©n Ä‘oÃ¡n lá»—i ká»¹ thuáº­t (Fault Diagnosis)  
- PhÃ¢n tÃ­ch rá»§i ro (Risk Analysis)  
- PhÃ¢n loáº¡i dá»¯ liá»‡u phá»©c táº¡p (Data Classification)

---

## ğŸ“š TÃ i liá»‡u tham kháº£o

1. Dempster, A.P. (1967). *Upper and Lower Probabilities Induced by a Multivalued Mapping.*  
2. Shafer, G. (1976). *A Mathematical Theory of Evidence.* Princeton University Press.  
3. Yager, R. (2014). *On the negation of probability distributions.*  
4. Yin et al. (2018). *Negation of Basic Probability Assignment in Dempsterâ€“Shafer Theory.*  
5. Wu et al. (2020). *Belief Entropy and Its Application in Evidence Theory.*

---

## ğŸ’¬ LiÃªn há»‡

Náº¿u báº¡n muá»‘n Ä‘Ã³ng gÃ³p, cáº£i thiá»‡n hoáº·c sá»­ dá»¥ng mÃ´ hÃ¬nh trong nghiÃªn cá»©u khÃ¡c, vui lÃ²ng táº¡o **issue** hoáº·c **pull request** táº¡i repository.  

---

> ğŸ“ˆ **Káº¿t luáº­n:**  
> MÃ´ hÃ¬nh káº¿t há»£p **Adaboost â€“ BPA â€“ Entropy Niá»m Tin** lÃ  hÆ°á»›ng tiáº¿p cáº­n hiá»‡u quáº£ cho bÃ i toÃ¡n phÃ¢n loáº¡i trong mÃ´i trÆ°á»ng dá»¯ liá»‡u khÃ´ng cháº¯c cháº¯n.  
> NghiÃªn cá»©u nÃ y gÃ³p pháº§n má»Ÿ rá»™ng kháº£ nÄƒng á»©ng dá»¥ng lÃ½ thuyáº¿t Dempsterâ€“Shafer trong trÃ­ tuá»‡ nhÃ¢n táº¡o vÃ  há»c mÃ¡y hiá»‡n Ä‘áº¡i.
